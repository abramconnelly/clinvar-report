#!/usr/bin/python

import arvados as arv
import arvados.commands.put as put
import sys
import os
import logging
import time
import json

#import argparse
#parser = argparse.ArgumentParser()
#parser.add_argument('--dry-run', action='store_true')
#parser.add_argument('--script-parameters', type=str, default="{}")
#args = parser.parse_args()

def machine_progress(bytes_written, bytes_expected):
    return "upload wrote {} total {}\n".format(
        bytes_written, -1 if (bytes_expected is None) else bytes_expected)

# Upload to Keep with error recovery.
# Return a uuid or raise an exception if there are too many failures.
def upload(source_dir, logger=None):
    if logger is None:
        logger = logging.getLogger("arvados")

    source_dir = os.path.abspath(source_dir)
    done = False
    if 'TASK_WORK' in os.environ:
        resume_cache = put.ResumeCache(os.path.join(arv.current_task().tmpdir, "upload-output-checkpoint"))
    else:
        resume_cache = put.ResumeCache(put.ResumeCache.make_path(Args(source_dir)))
    reporter = put.progress_writer(machine_progress)
    bytes_expected = put.expected_bytes_for([source_dir])
    backoff = 1
    outuuid = None
    while not done:
        try:
            out = put.ArvPutCollectionWriter.from_cache(resume_cache, reporter, bytes_expected)
            out.do_queued_work()
            out.write_directory_tree(source_dir, max_manifest_depth=0)
            outuuid = out.finish()
            done = True
        except KeyboardInterrupt as e:
            logger.critical("caught interrupt signal 2")
            raise e
        except Exception as e:
            logger.exception("caught exception:")
            backoff *= 2
            if backoff > 256:
                logger.critical("Too many upload failures, giving up")
                raise e
            else:
                logger.warning("Sleeping for %s seconds before trying again" % backoff)
                time.sleep(backoff)
    return outuuid


def print_help():
  print "usage:"
  print "  job-uuid             Prints job UUID (JOB_UUID)"
  print "  task-uuid            Prints task UUID (TASK_UUID)"
  print "  job-src              Prints Crunch source directory (CRUNCH_SRC)"
  print "  keep                 Prints Keep mount point (TASK_KEEPMOUNT)"
  print "  script_parameters    Return JSON string of the 'script_parameters' passed into the job"
  print "  task <op> ...        Execute task instruction (create|progress|finish|fail)"
  print "    task sequence              Report the task sequence (0 for parent)"
  print "    task parameters            Return JSON string of the 'parameters' passed into the task"
  print "    task create [params]       Create a task.  Params is a JSON string containing the parameters.  '-' for stdin."
  print "    task progress <real>       Report a progress"
  print "    task finish [dir]          Put [dir] directory in keep, use it as the output collection and finish (successfully) the task"
  print "    task success <pdh>         Return task success and use <pdh> as the output collection"
  print "    task fail                  Fail the task"

api = arv.api('v1')

cmd = "help"
if len(sys.argv) > 1:
  cmd = sys.argv[1]

val = ""
if len(sys.argv) > 2:
  val = sys.argv[2]

outdir = "."
progress = 0.5
pdh = "cafe+1"

params = {}
if cmd == "task" and val == "create" and len(sys.argv) > 3:
  v = sys.argv[3]
  if v == "-":
    v = sys.stdin.read()
  params = json.loads(v)



if cmd == "setup":
  wd=arv.current_task().tmpdir
  print "#!/bin/bash"
  print "#"
  print ""
  print 'export PATH="$PATH:$CRUNCH_SRC:$CRUNC_SRC/crunch_scripts"'
  print "cd", wd
  print "mkdir -p output"
  print "mkdir -p tmpdir"
  print "cd output"

elif cmd == "job-uuid":
  print os.environ['JOB_UUID']
  sys.exit(0)

elif cmd == "task-uuid":
  print os.environ['TASK_UUID']
  sys.exit(0)

elif cmd == "task-wd":
  print arv.current_task().tmpdir
  sys.exit(0)

elif cmd == "job-src":
  print os.environ['CRUNCH_SRC']
  sys.exit(0)

elif cmd == "keep":
  print os.environ['TASK_KEEPMOUNT']
  sys.exit(0)

elif cmd == "script_parameters":
  jobp = arv.current_job()['script_parameters']
  print json.dumps(jobp)
  sys.exit(0)

elif cmd == "task":
  if len(val) == 0:
    print "ERROR: Invalid value for create"
    show_help()
    sys.exit(1)

  if val == "create":

    arv.api().job_tasks().create( body={
      'job_uuid':arv.current_job()['uuid'],
      'created_by_job_task_uuid':arv.current_task()['uuid'],
      'sequence':1,
      'parameters':params
    }).execute()

  elif val == "parameters":
    if len(arv.current_task()['parameters']) > 0:
      taskp = arv.current_task()['parameters']
      print json.dumps(taskp)
    else:
      print "{}"
    sys.exit(0)



  elif val == "sequence":
    print arv.current_task()['sequence']
    sys.exit(0)

  elif val == "progress":

    arv.api().job_tasks().update( uuid=arv.current_task()['uuid'],
      body={
        'progress': progress
      }).execute()

  elif val == "success":

    arv.api().job_tasks().update( uuid=arv.current_task()['uuid'],
      body={
        'output': pdh,
        'success': True,
        'progress':1.0
      }).execute()

    sys.exit(0)

  elif val == "finish":

    outcollection = upload( outdir )

    arv.api().job_tasks().update( uuid=arv.current_task()['uuid'],
      body={
        'output': outcollection,
        'success': True,
        'progress':1.0
      }).execute()

    sys.exit(0)

  elif val == "fail":

    arv.api().job_tasks().update( uuid=arv.current_task()['uuid'],
      body={
        'success': False,
        'progress':1.0
      }).execute()

    sys.exit(1)

else:
  print_help()
  sys.exit(1)


sys.exit(0)
